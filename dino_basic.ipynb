{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial DINO model\n",
    "\n",
    "This notebook has the first pass at creating a tree classification model based on DINOv2. It takes as input a tree image, and outputs a class. The available classes are determined by the `classes.json` file for the Laurentian trees dataset.\n",
    "\n",
    "DINOv2 is run over the image, and then linear probing is done on the output tokens. It's got really bad accuracy and is having difficulty learning.\n",
    "\n",
    "A number of things could be tried here to improve it:\n",
    "- Using KNN instead of linear probing, since these classes may not be linearly separable even in token space\n",
    "- Token-level classification (Martin thinks this is the best approach)\n",
    "- Adjusting the image pre-processing. Currently they're all scaled to 256*256, which could cause stretching for non-square inputs\n",
    "- Only using tokens where the tree is located. Since one version of the input uses masked tree images with transparent backgrounds, we could try to just use the non-transparent pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/miniconda3/envs/scratch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from transformers import Dinov2Model, Dinov2PreTrainedModel\n",
    "from PIL import Image\n",
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "\n",
    "class TreeDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform, zones=['Z1', 'Z2'], class_map_path='./data/classes.json'):\n",
    "        with open(class_map_path, 'r') as f:\n",
    "            self.class_map = {v:int(k) for k, v in json.load(f).items()}\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.classes = [d for d in os.listdir(root_dir)]\n",
    "        self.image_files = []\n",
    "        self.transform = transform\n",
    "        for c in self.classes:\n",
    "            for img in os.listdir(os.path.join(root_dir, c)):\n",
    "                if any(z for z in zones if z in img):\n",
    "                    self.image_files.append((os.path.join(root_dir, c, img), self.class_map[c]))\n",
    "        self.toTensor = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, c = self.image_files[idx]\n",
    "        img_np = np.array(Image.open(img_path))[:,:,:3]\n",
    "        transformed = self.transform(image=img_np)['image']\n",
    "        return self.toTensor(transformed), torch.tensor(c)\n",
    "\n",
    "# These are the mean/std I took from the complete tiff of Z1\n",
    "ADE_MEAN = np.array([51.61087416176021, 70.54108897685563, 43.65073194868197]) / 255\n",
    "ADE_STD = np.array([66.21302035582556, 82.09431586857384, 54.93294965405881]) / 255\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(width=224, height=224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Normalize(mean=ADE_MEAN, std=ADE_STD),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(width=224, height=224),\n",
    "    A.Normalize(mean=ADE_MEAN, std=ADE_STD),\n",
    "])\n",
    "\n",
    "train_dataset = TreeDataset('./data/tree_classification', train_transform)\n",
    "val_dataset = TreeDataset('./data/tree_classification', val_transform, zones=['Z3'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Pick this up tomorrow: https://github.com/NielsRogge/Transformers-Tutorials/blob/master/DINOv2/Train_a_linear_classifier_on_top_of_DINOv2_for_semantic_segmentation.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Dinov2ForClassification were not initialized from the model checkpoint at facebook/dinov2-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dinov2ForClassification(\n",
       "  (dinov2): Dinov2Model(\n",
       "    (embeddings): Dinov2Embeddings(\n",
       "      (patch_embeddings): Dinov2PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Dinov2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x Dinov2Layer(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attention): Dinov2Attention(\n",
       "            (attention): Dinov2SelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): Dinov2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (layer_scale1): Dinov2LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Dinov2MLP(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_scale2): Dinov2LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=196608, out_features=29, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dinov2ForClassification(Dinov2PreTrainedModel):\n",
    "  def __init__(self, config):\n",
    "    super().__init__(config)\n",
    "    self.config = config\n",
    "    self.dinov2 = Dinov2Model(config)\n",
    "    self.classifier = nn.Linear(config.hidden_size * 256, config.num_labels)\n",
    "\n",
    "\n",
    "  def forward(self, pixel_values, output_hidden_states=False, output_attentions=False, labels=None):\n",
    "    # use frozen features\n",
    "    outputs = self.dinov2(pixel_values,\n",
    "                            output_hidden_states=output_hidden_states,\n",
    "                            output_attentions=output_attentions)\n",
    "    \n",
    "    # get the patch embeddings - so we exclude the CLS token\n",
    "    patch_embeddings = torch.flatten(outputs.last_hidden_state[:,1:,:], start_dim=1)\n",
    "\n",
    "    # convert to logits and upsample to the size of the pixel values\n",
    "    logits = self.classifier(patch_embeddings)\n",
    "\n",
    "    return nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "model = Dinov2ForClassification.from_pretrained(\"facebook/dinov2-base\", num_labels=29)\n",
    "\n",
    "# freeze DINOv2 parameters\n",
    "for name, param in model.named_parameters():\n",
    "  if name.startswith(\"dinov2\"):\n",
    "    param.requires_grad = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [01:50<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 0.1987968183538941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:26<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val loss: 0.20195730768937833\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [01:45<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 0.1961812807714741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:25<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val loss: 0.19953692594344674\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [01:44<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 0.19311613029590952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:25<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val loss: 0.19674139375129515\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [01:46<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 0.19124460259447573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:25<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val loss: 0.19552859188764773\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [01:45<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 0.1904920567078019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:25<00:00, 11.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val loss: 0.19482034156002948\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [01:45<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 0.1897978750583068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:25<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val loss: 0.19429856982222946\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [01:44<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 0.18930892501603275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:25<00:00, 11.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val loss: 0.1939089653418236\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [01:43<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 0.188947942065546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:24<00:00, 11.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val loss: 0.19351345022109775\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [01:44<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 0.18862033156272306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:25<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val loss: 0.19318987811144275\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1143/1143 [01:45<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 0.18819623375971486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:24<00:00, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val loss: 0.1928560747928226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "epochs = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "epoch_train_losses = []\n",
    "epoch_val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  train_loss = 0\n",
    "  val_loss = 0\n",
    "  print(\"Epoch:\", epoch)\n",
    "\n",
    "  for idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "    data = batch[0].to(device)\n",
    "    targets = nn.functional.one_hot(batch[1], num_classes=29).float().to(device)\n",
    "    \n",
    "    # forward pass\n",
    "    outputs = model(data)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_loss += loss.item() / targets.shape[0]\n",
    "  \n",
    "  train_loss /= len(train_dataloader)\n",
    "  print(f'  Train loss: {train_loss}')\n",
    "\n",
    "  for idx, batch in enumerate(tqdm(val_dataloader)):\n",
    "    data = batch[0].to(device)\n",
    "    targets = nn.functional.one_hot(batch[1], num_classes=29).float().to(device)\n",
    "    outputs = model(data)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    optimizer.zero_grad()\n",
    "    val_loss += loss.item() / targets.shape[0]\n",
    "  \n",
    "  val_loss /= len(val_dataloader)\n",
    "  print(f'  Val loss: {val_loss}')\n",
    "  epoch_train_losses.append(train_loss)\n",
    "  epoch_val_losses.append(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1987968183538941, 0.1961812807714741, 0.19311613029590952, 0.19124460259447573, 0.1904920567078019, 0.1897978750583068, 0.18930892501603275, 0.188947942065546, 0.18862033156272306, 0.18819623375971486]\n",
      "[0.20195730768937833, 0.19953692594344674, 0.19674139375129515, 0.19552859188764773, 0.19482034156002948, 0.19429856982222946, 0.1939089653418236, 0.19351345022109775, 0.19318987811144275, 0.1928560747928226]\n"
     ]
    }
   ],
   "source": [
    "print(epoch_train_losses)\n",
    "print(epoch_val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
